{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Преобразование данных в нужный формат (COCO format)\n",
    "\n",
    "Используемые библиотеки:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from cropper.utils import get_full_boxes\n",
    "\n",
    "DATA_PATH = r'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Основные функции:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def is_point_in_image(point: List[int], image_bbox: List) -> bool:\n",
    "    \"\"\" Проверка точки на попадание на изображение. \"\"\"\n",
    "    return image_bbox[0] <= point[0] < image_bbox[2] and image_bbox[1] <= point[1] < image_bbox[3]\n",
    "\n",
    "\n",
    "def get_bbox(quad: List, image_bbox: List) -> List:\n",
    "    \"\"\" Получение bbox с учётом краёв изображения. \"\"\"\n",
    "    xA = max(min([pos[0] for pos in quad]), image_bbox[0])\n",
    "    yA = max(min([pos[1] for pos in quad]), image_bbox[1])\n",
    "    xB = min(max([pos[0] for pos in quad]), image_bbox[2])\n",
    "    yB = min(max([pos[1] for pos in quad]), image_bbox[3])\n",
    "    label_bbox = [xA, yA, xB - xA, yB - yA]\n",
    "    return label_bbox\n",
    "\n",
    "\n",
    "def get_keypoints(quad: List, image_bbox: List) -> List:\n",
    "    \"\"\" Получение ключевых точек. \"\"\"\n",
    "    assert quad[0][0] < quad[1][0] and quad[1][1] < quad[2][1] and quad[2][0] > quad[3][0] and quad[3][1] > quad[0][1]\n",
    "    keypoints = []\n",
    "    for point in quad:\n",
    "        if is_point_in_image(point, image_bbox):\n",
    "            keypoints.extend(point + [2])\n",
    "        else:\n",
    "            keypoints.extend(point + [1])\n",
    "    return keypoints\n",
    "\n",
    "\n",
    "def write_coco_format(img_paths: List[str], ann_paths: List[str], target_json: str) -> None:\n",
    "    \"\"\" Основная функция преобразования в COCO-формат. \"\"\"\n",
    "    json_content = {\n",
    "        'images': [],\n",
    "        'annotations': [],\n",
    "        'categories': [\n",
    "            {'id': 1, 'name': 'document'}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    parent_dir = os.path.dirname(target_json)\n",
    "    for id, (img_path, ann_path) in tqdm(enumerate(zip(img_paths, ann_paths))):\n",
    "        image = cv2.imread(img_path)\n",
    "        if img_path.startswith(parent_dir):\n",
    "            img_path = img_path[len(parent_dir) + 1:]\n",
    "        image_data = {\n",
    "            'file_name': img_path,\n",
    "            'height': image.shape[0],\n",
    "            'width': image.shape[1],\n",
    "            'id': id\n",
    "        }\n",
    "        json_content['images'].append(image_data)\n",
    "\n",
    "        quad = json.load(open(ann_path, 'r'))['quad']\n",
    "        image_bbox = [0, 0, image.shape[1], image.shape[0]]\n",
    "        label_bbox = get_bbox(quad, image_bbox)\n",
    "        keypoints = get_keypoints(quad, image_bbox)\n",
    "\n",
    "        ann_data = {\n",
    "            'segmentation': [single_coord for coord_pair in quad for single_coord in coord_pair],\n",
    "            'keypoints': keypoints,\n",
    "            'num_keypoints': 4,\n",
    "            'area': image.shape[0] * image.shape[1],\n",
    "            'iscrowd': 0,\n",
    "            'image_id': id,\n",
    "            'bbox': label_bbox,\n",
    "            'category_id': 1,\n",
    "            'id': id\n",
    "        }\n",
    "        json_content['annotations'].append(ann_data)\n",
    "\n",
    "    with open(target_json, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(json_content, json_file, indent=None)\n",
    "\n",
    "\n",
    "def get_filenames(data_path: str, test_gt_path: str) -> Tuple[Dict[str, List[str]], Dict[str, List[str]]]:\n",
    "    \"\"\" Разбиение выборки на обучающие и тестовые, получение файлов изображений и аннотаций. \"\"\"\n",
    "    img_paths = {'train': [], 'train_det': [], 'train_crop': [], 'test': []}\n",
    "    ann_paths = {'train': [], 'train_det': [], 'train_crop': [], 'test': []}\n",
    "\n",
    "    with open(test_gt_path, 'r') as f:\n",
    "        json_contents = json.load(f)\n",
    "        test_samples = list(map(lambda name: name.split('|')[-1], json_contents.keys()))\n",
    "\n",
    "    for root, dirnames, filenames in os.walk(data_path):\n",
    "        for filename in filter(lambda x: x.endswith('.json') and len(dirnames) == 0, filenames):\n",
    "            if filename in test_samples:\n",
    "                cur_sets = ['test']\n",
    "            else:\n",
    "                doc_num = int(filename[-10:-8])\n",
    "                internal_num = int(filename[-7:-5])\n",
    "                if doc_num > 10 and internal_num > 10:\n",
    "                    cur_sets = ['train', 'train_det']\n",
    "                else:\n",
    "                    cur_sets = ['train', 'train_crop']\n",
    "            for cur_set in cur_sets:\n",
    "                ann_paths[cur_set].append(os.path.join(root, filename))\n",
    "                img_paths[cur_set].append(ann_paths[cur_set][-1].replace('ground_truth', 'images').replace('.json', '.png'))\n",
    "\n",
    "    return img_paths, ann_paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Преобразование данных:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "img_paths, ann_paths = get_filenames(os.path.join(DATA_PATH, 'midv500_compressed'), 'gt.json')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "338f8e1712be4cc980e4ba2cfa731450"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_coco_format(img_paths['train'], ann_paths['train'], os.path.join(DATA_PATH, 'train_gt.json'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21790230072b48d687b8cc19c7eeab0e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_coco_format(img_paths['train_det'], ann_paths['train_det'], os.path.join(DATA_PATH, 'train_det_gt.json'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "43f72413ce3e44d7a77f6dced8d1e076"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_coco_format(img_paths['train_crop'], ann_paths['train_crop'], os.path.join(DATA_PATH, 'train_crop_gt.json'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27d03fd4dfec49afaa0b418c530a1d5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_coco_format(img_paths['test'], ann_paths['test'], os.path.join(DATA_PATH, r'test_gt.json'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Создадим файл с боксами, необходимыми для обучения и использования HRNet (в качестве боксов возьмём изображения целиком):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_full_boxes(r'data\\train_gt.json', r'cropper\\train_boxes.json')\n",
    "get_full_boxes(r'data\\test_gt.json', r'cropper\\test_boxes.json')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
